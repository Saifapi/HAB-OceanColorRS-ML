{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMXaHLapZLq/90yGmDjJSIK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Connect with the Drive**"],"metadata":{"id":"TqAWlfxAJHhs"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pxKqH5pGvDr"},"outputs":[],"source":["# This is an essential part to work in Google Colaboratory\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["# **To show the Data Structure**"],"metadata":{"id":"_5iLiydjJb8s"}},{"cell_type":"code","source":["import xarray as xr\n","\n","# Load any NetCDF file (example: SST)\n","ds = xr.open_dataset(\"/content/drive/My Drive/File_name.nc\")\n","print(ds)\n","\n","import numpy as np\n","\n","# Extract latitudes and longitudes\n","latitudes = ds[\"latitude\"].values  # Check your dataset for actual names, e.g., \"lat\"\n","longitudes = ds[\"longitude\"].values  # Sometimes it is \"lon\"\n","\n","# Compute spatial resolution (assuming uniform spacing)\n","lat_res = np.abs(latitudes[1] - latitudes[0])  # Latitude resolution (degrees)\n","lon_res = np.abs(longitudes[1] - longitudes[0])  # Longitude resolution (degrees)\n","\n","print(f\"Spatial Resolution: {lat_res:.6f}¬∞ x {lon_res:.6f}¬∞\")"],"metadata":{"id":"HXuvJEi6Gz10"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Crop the Dataset with Shapefile**"],"metadata":{"id":"aUsJYP4iJm7K"}},{"cell_type":"code","source":["import xarray as xr\n","import rioxarray as rxr\n","import geopandas as gpd\n","import matplotlib.pyplot as plt\n","\n","# ---- Step 1: Load the NetCDF File ----\n","nc_file = \"/content/drive/My Drive/File_name.nc\"  # Change this to your NetCDF file path\n","ds = xr.open_dataset(nc_file)\n","\n","# ---- Step 2: Open the Shapefile ----\n","shapefile_path = \"/content/drive/My Drive/Shapefile_name.shp\"  # Change this to your shapefile path\n","gdf = gpd.read_file(shapefile_path)\n","\n","# Ensure the shapefile CRS matches NetCDF file CRS\n","gdf = gdf.to_crs(\"EPSG:4326\")  # Convert to WGS 1984 (latitude/longitude)\n","\n","# ---- Step 3: Convert NetCDF Dataset to Raster Format & Clip ----\n","ds = ds.rio.write_crs(\"EPSG:4326\")  # Assign CRS if missing\n","\n","# Clip the dataset using the shapefile\n","ds_cropped = ds.rio.clip(gdf.geometry, gdf.crs)\n","\n","# ---- Step 4: Save the Cropped NetCDF File ----\n","output_nc_path = \"/content/drive/My Drive/File_name_cropped.nc\"  # Change to your output path\n","ds_cropped.to_netcdf(output_nc_path)\n","\n","print(f\"Cropped NetCDF file saved at: {output_nc_path}\")\n","\n","# ---- Step 5: Select a Specific Day to Plot (e.g., First Available Date) ----\n","selected_date = ds_cropped.time[0].values  # Select the first date\n","parameter_name_day = ds_cropped[\"Parameter_name\"].sel(time=selected_date)  # Plot Parameter\n","\n","# ---- Step 6: Plot the Cropped Parameter Data ----\n","plt.figure(figsize=(8, 6))\n","chl_day.plot(cmap=\"coolwarm\")  # Change colormap if needed\n","plt.title(f\"Cropped Parameter_name Data for {str(selected_date)[:10]}\")\n","plt.xlabel(\"Longitude\")\n","plt.ylabel(\"Latitude\")\n","plt.show()"],"metadata":{"id":"29fBMidAH2Xy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Time-Series of Average High-Low Parameter Value**"],"metadata":{"id":"8H86XNZkb2oD"}},{"cell_type":"code","source":["import xarray as xr\n","import matplotlib.pyplot as plt\n","\n","# Load the NetCDF file (Replace with your actual file path)\n","file_path = \"/content/drive/My Drive/File_name_cropped.nc\"\n","ds = xr.open_dataset(file_path)\n","\n","# Replace 'Parameter_name' with the actual variable name in your dataset\n","parameter = ds['Parameter_name']\n","\n","# Compute the daily mean parameter (averaged over the spatial domain)\n","parameter_daily_mean = parameter.mean(dim=[\"latitude\", \"longitude\"])\n","\n","# Find max and min values\n","max_value = parameter_daily_mean.max().values\n","min_value = parameter_daily_mean.min().values\n","\n","# Find corresponding dates\n","max_date = parameter_daily_mean.time[parameter_daily_mean.argmax()].values\n","min_date = parameter_daily_mean.time[parameter_daily_mean.argmin()].values\n","\n","# === Plot the Time Series with Max & Min Highlighted ===\n","plt.figure(figsize=(24, 12))\n","plt.plot(parameter_daily_mean.time, parameter_daily_mean, label=\"Daily Parameter_name\", color=\"blue\")\n","\n","# Mark the highest and lowest points\n","plt.scatter(max_date, max_value, color=\"red\", label=f\"Max: {max_value:.2f} on {str(max_date)[:10]}\", zorder=3)\n","plt.scatter(min_date, min_value, color=\"green\", label=f\"Min: {min_value:.2f} on {str(min_date)[:10]}\", zorder=3)\n","\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Parameter (Original Unit)\")\n","plt.title(\"Daily Parameter (2021-2024)\")\n","plt.legend()\n","plt.grid()\n","plt.show()"],"metadata":{"id":"DVwzfrBCbwPs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Map of Parameter**"],"metadata":{"id":"xl1BZ3qddH7F"}},{"cell_type":"code","source":["import xarray as xr\n","import matplotlib.pyplot as plt\n","import cartopy.crs as ccrs\n","import cartopy.feature as cfeature\n","\n","# Load the NetCDF file (Replace with your file path)\n","file_path = \"/content/drive/My Drive/File_name_cropped.nc\"\n","ds = xr.open_dataset(file_path)\n","\n","# Replace 'Parameter_name' with the actual variable name in your dataset\n","parameter = ds['Parameter_name']\n","\n","# Plot parameter as a Map for a Specific Day ===\n","selected_date = \"2023-08-16\"  # Change this to your desired date\n","parameter_day = parameter.sel(time=selected_date, method=\"nearest\")\n","\n","plt.figure(figsize=(10, 6))\n","ax = plt.axes(projection=ccrs.PlateCarree())\n","parameter_day.plot.pcolormesh(ax=ax, cmap=\"viridis\", transform=ccrs.PlateCarree())\n","\n","ax.coastlines()\n","ax.add_feature(cfeature.BORDERS, linestyle=\":\")\n","ax.gridlines(draw_labels=True)\n","\n","plt.title(f\"Parameter on {selected_date}\")\n","plt.show()"],"metadata":{"id":"nqiIfPZSc1_x"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Checking the High-Low value**"],"metadata":{"id":"XD6FCTHHfnfP"}},{"cell_type":"code","source":["import xarray as xr\n","\n","# Load the original NetCDF file\n","file_path = \"/content/drive/My Drive/File_name_cropped.nc\"  # Update path if needed\n","ds = xr.open_dataset(file_path)\n","\n","# Extract min and max values\n","parameter_min, parameter_max = ds[\"Parameter_name\"].min().item(), ds[\"Parameter_name\"].max().item()\n","\n","# Print results in correct units\n","print(f\"üå°Ô∏è parameter (Original Unit): {parameter_min:.2f}Original Unit to {parameter_max:.2f}Original Unit\")"],"metadata":{"id":"zMhX4E7Kfm8I"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Checking Parameter Metadata**"],"metadata":{"id":"f3E6dLX1gm4I"}},{"cell_type":"code","source":["import xarray as xr\n","\n","# Load the original NetCDF file\n","file_path = \"/content/drive/My Drive/File_name_cropped.nc\"  # Update with actual path\n","ds = xr.open_dataset(file_path)\n","\n","# Display dataset details\n","print(ds)\n","\n","# Print attributes of each variable (to check units)\n","for var in ds.variables:\n","    print(f\"\\nüîπ Parameter: {var}\")\n","    print(ds[var].attrs)  # Prints metadata, including units if available\n"],"metadata":{"id":"c2xDLA7bggSm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Normalization of Dataset (0-255 pixel)**"],"metadata":{"id":"-7Pj0a-bKlSX"}},{"cell_type":"code","source":["import xarray as xr\n","from sklearn.preprocessing import MinMaxScaler\n","import os\n","\n","# Load original NetCDF file\n","file_path = \"/content/drive/My Drive/File_name_cropped.nc\"  # Change this to your actual file path\n","ds = xr.open_dataset(file_path)\n","\n","# Define output folder\n","output_folder = \"/content/drive/My Drive/Normalized_NetCDF\"\n","os.makedirs(output_folder, exist_ok=True)  # Create folder if it doesn‚Äôt exist\n","\n","# Define parameters to scale\n","parameters = ['Parameter_name']\n","\n","# Apply Min-Max Scaling (0 to 255) for CNN\n","ds_cnn = ds.copy()\n","scaler_0_255 = MinMaxScaler(feature_range=(0, 255))\n","for param in parameters:\n","    data = ds_cnn[param].values.reshape(-1, 1)  # Reshape for sklearn\n","    scaled_data = scaler_0_255.fit_transform(data).reshape(ds_cnn[param].shape)\n","    ds_cnn[param] = (ds_cnn[param].dims, scaled_data)\n","\n","# Save the CNN-normalized dataset\n","cnn_output_path = os.path.join(output_folder, \"normalized_0_255.nc\")\n","ds_cnn.to_netcdf(cnn_output_path)\n","print(f\"CNN Normalization (0-255) applied and saved as {cnn_output_path}\")\n","\n","print(\"\\n‚úÖ Normalization completed successfully! Files saved in 'Normalized NetCDF' folder.\")"],"metadata":{"id":"2JW-pWezKlsV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **EDA of Normalize Dataset**"],"metadata":{"id":"AhfgjzUxOKCN"}},{"cell_type":"code","source":["import xarray as xr\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Load the normalized dataset (0-255 scaled file for CNN)\n","file_path = \"/content/drive/My Drive/normalized_0_255.nc\"  # Update the path if needed\n","ds = xr.open_dataset(file_path)\n","\n","# Define parameters for EDA\n","parameter = ['Parameter_name']\n","\n","# üìå **1. Dataset Overview**\n","print(\"\\nüîπ Dataset Structure:\\n\", ds)\n","print(\"\\nüîπ Dataset Statistics:\\n\", ds.to_dataframe().describe())\n","\n","# üìå **2. Check Missing Values**\n","print(\"\\nüîπ Missing Values:\\n\", ds.to_dataframe().isnull().sum())\n","\n","# üìå **3. Plot Time Series Trends (Global Mean Values)**\n","plt.figure(figsize=(12, 5))\n","for param in parameters:\n","    ds[param].mean(dim=['latitude', 'longitude']).plot(label=param)\n","plt.legend()\n","plt.title(\"üìà Daily Trends of Parameter\")\n","plt.xlabel(\"Time\")\n","plt.ylabel(\"Pixel Intensity (0-255)\")\n","plt.show()\n","\n","# üìå **4. Plot Histograms & Distributions**\n","fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n","for i, param in enumerate(parameters):\n","    sns.histplot(ds[param].values.flatten(), bins=50, kde=True, ax=axes[i])\n","    axes[i].set_title(f\"Distribution of {param}\")\n","plt.tight_layout()\n","plt.show()\n","\n","# üìå **6. Generate Spatial Maps (First Time Step)**\n","for param in parameter:\n","    ds[param].isel(time=0).plot(cmap=\"viridis\", figsize=(8, 6))\n","    plt.title(f\"üó∫Ô∏è Spatial Distribution of {param} (First Time Step)\")\n","    plt.show()\n","\n","print(\"\\n‚úÖ CNN-Based EDA Completed Successfully!\")"],"metadata":{"id":"CLL4GercOKay"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Split daily images from the original Combined Dataset**"],"metadata":{"id":"_j3IwAypeFWM"}},{"cell_type":"code","source":["import xarray as xr\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","from PIL import Image  # For resizing images\n","\n","# Define your Google Drive base path\n","base_path = \"/content/drive/My Drive/Images\"\n","\n","# Define output folders for images inside Google Drive\n","output_dirs = {\n","    \"Parameter_name\": os.path.join(base_path, \"Parameter\")}\n","\n","# Create directories if they don‚Äôt exist\n","for path in output_dirs.values():\n","    os.makedirs(path, exist_ok=True)\n","\n","# Load your normalized NetCDF file\n","file_path = \"/content/drive/My Drive/normalized_0_255.nc\"  # Update this path\n","ds = xr.open_dataset(file_path)\n","\n","# Define colormaps for visualization\n","colormaps = {\n","    \"{Parameter}\": \"choose colorcode\"}   # Choose color for Parameter\n","\n","# Define target image resolution (change if needed)\n","target_size = (512, 512)  # Resize images to 512x512 pixels\n","\n","# Convert each parameter to color images\n","for param in [\"Parameter_name\"]:\n","    data = ds[param]  # Extract parameter data\n","\n","    # Get the corresponding colormap key\n","    colormap_key = {\n","        \"Parameter_name\": \"Parameter\"}.get(param, param)  # Default to param if not found\n","\n","    for i, timestamp in enumerate(data.time):\n","        img_data = data.sel(time=timestamp).values  # Extract 2D array\n","        img_data = img_data.squeeze()\n","        img_data = np.nan_to_num(img_data, nan=0)  # Convert NaN (land) to 0 (black)\n","\n","        # Fix flipping and rotation issues\n","        img_data = np.flipud(img_data)  # Flip vertically\n","        #img_data = np.fliplr(img_data)  # Flip horizontally\n","\n","        # Create and save temporary image\n","        plt.figure(figsize=(4, 4))\n","        plt.axis(\"off\")\n","        # Use colormap_key instead of param directly\n","        plt.imshow(img_data, cmap=colormaps[colormap_key])  # Apply colormap\n","        #plt.colorbar(label=param)\n","\n","        # Temporary image path\n","        temp_filename = f\"{output_dirs[param]}/temp_{i:04d}.png\"\n","        plt.savefig(temp_filename, bbox_inches=\"tight\", pad_inches=0)\n","        plt.close()\n","\n","        # Resize image using PIL\n","        img = Image.open(temp_filename)\n","        img_resized = img.resize(target_size, Image.Resampling.LANCZOS)\n","\n","        # Final resized image path\n","        final_filename = f\"{output_dirs[param]}/{param}_{i:04d}.png\"\n","        img_resized.save(final_filename)\n","\n","        # Remove temporary image\n","        os.remove(temp_filename)\n","\n","    print(f\"‚úÖ Saved {len(data.time)} resized images for {param} in Google Drive.\")"],"metadata":{"id":"h_Vf1LfTeFCX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Dataset Labeling**"],"metadata":{"id":"nO3uLRFElGEc"}},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","\n","def convert_threshold_to_pixel(original_value, param_min, param_max):\n","    \"\"\"\n","    Convert an original threshold value to its corresponding pixel value\n","    for an 8-bit (0-255) normalized image.\n","    \"\"\"\n","    return (original_value - param_min) / (param_max - param_min) * 255\n","\n","# ----- Define thresholds and ranges for each parameter -----\n","\n","# Example values for Parameter (in Original Unit)\n","parameter_min = give value        # Original minimum Parameter\n","parameter_max = give value        # Original maximum Parameter\n","parameter_topic_lower_orig = give value   # topic lower threshold in Original Unit for Parameters\n","parameter_topic_upper_orig = give value   # topic upper threshold in Original Unit for Parameters\n","\n","# Convert each parameter's thresholds to pixel values\n","Parameter_topic_lower_px = convert_threshold_to_pixel(parameter_topic_lower_orig, parameter_min, parameter_max)\n","Parameter_topic_upper_px = convert_threshold_to_pixel(parameter_topic_upper_orig, parameter_min, parameter_max)\n","\n","print(\"Parameter topic pixel range: {:.2f} - {:.2f}\".format(parameter_topic_lower_px, parameter_topic_upper_px))\n","\n","# ----- Define input and output directories for parameter -----\n","input_dirs = {\n","    \"parameter\": \"/content/drive/My Drive/Images/Parameter\"}      # Folder with Parameter PNG files\n","\n","output_dirs = {\n","    \"parameter\": \"/content/drive/My Drive/Images/Parameter_Labeled\"}   # Output folder for labeled Parameter images\n","\n","# Create output directories if they don't exist\n","for path in output_dirs.values():\n","    os.makedirs(path, exist_ok=True)\n","\n","def process_images_for_parameter(param_key, lower_px, upper_px):\n","    \"\"\"\n","    Process all images for a given parameter.\n","    For each image:\n","      - Read the normalized (0-255) grayscale image.\n","      - Create a binary mask: set pixel to 1 (Topic) if its value is between lower_px and upper_px, else 0.\n","      - Save the binary mask as a PNG (multiplying by 255 for visualization).\n","    \"\"\"\n","    input_dir = input_dirs[param_key]\n","    output_dir = output_dirs[param_key]\n","    image_files = sorted([f for f in os.listdir(input_dir) if f.lower().endswith('.png')])\n","\n","    for i, fname in enumerate(image_files):\n","        image_path = os.path.join(input_dir, fname)\n","        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","        # Create binary mask: 1 for HAB area, 0 for non-HAB\n","        binary_mask = np.where((img >= lower_px) & (img <= upper_px), 1, 0).astype(np.uint8)\n","\n","        # Save the binary mask as PNG; multiply by 255 for display purposes (0 remains 0, 1 becomes 255)\n","        output_path = os.path.join(output_dir, fname)\n","        cv2.imwrite(output_path, binary_mask * 255)\n","\n","        if (i+1) % 100 == 0 or (i+1) == len(image_files):\n","            print(f\"[{param_key.upper()}] Processed {i+1}/{len(image_files)} images.\")\n","\n","    print(f\"Finished processing {param_key.upper()} images. Labeled images saved in {output_dir}\")\n","\n","# Process images for each parameter using its respective threshold pixel values\n","process_images_for_parameter(\"parameter\", parameter_bloom_lower_px, parameter_bloom_upper_px)"],"metadata":{"id":"PYbP4vc9lFwP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Dataset spliting into test, train & val**"],"metadata":{"id":"5cl_hJ9xpi2j"}},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","\n","# Define paths\n","base_dir = \"/content/drive/My Drive/Images\"  # Original images\n","output_dir = \"/content/drive/My Drive/Images/Split_Images\"  # Destination for split images\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Categories: SST, SSS, Chl-a\n","categories = [\"Parameter\"]\n","split_ratios = {\"train\": 0.7, \"val\": 0.15, \"test\": 0.15}\n","\n","# Function to split and copy images\n","def split_and_copy(category):\n","    print(f\"Processing: {category}\")\n","\n","    # Define input directories\n","    rgb_dir = os.path.join(base_dir, category)\n","    label_dir = os.path.join(base_dir, f\"{category}_Labeled\")\n","\n","    # Define output directories\n","    for split in [\"train\", \"val\", \"test\"]:\n","        os.makedirs(os.path.join(output_dir, category, split), exist_ok=True)\n","        os.makedirs(os.path.join(output_dir, f\"{category}_Labeled\", split), exist_ok=True)\n","\n","    # Get list of image files (sorted to avoid shuffling mismatched pairs)\n","    image_files = sorted([f for f in os.listdir(rgb_dir) if f.endswith(('.png', '.jpg', '.jpeg'))])\n","    random.seed(42)\n","    random.shuffle(image_files)\n","\n","    # Determine split sizes\n","    total = len(image_files)\n","    train_end = int(total * split_ratios[\"train\"])\n","    val_end = train_end + int(total * split_ratios[\"val\"])\n","\n","    # Perform splitting\n","    split_data = {\n","        \"train\": image_files[:train_end],\n","        \"val\": image_files[train_end:val_end],\n","        \"test\": image_files[val_end:]\n","    }\n","\n","    # Copy images to respective folders\n","    for split, files in split_data.items():\n","        for file in files:\n","            shutil.copy(os.path.join(rgb_dir, file), os.path.join(output_dir, category, split, file))\n","            shutil.copy(os.path.join(label_dir, file), os.path.join(output_dir, f\"{category}_Labeled\", split, file))\n","\n","    print(f\"‚úÖ {category} and {category}_Labeled split successfully!\")\n","\n","# Run the splitting process\n","for cat in categories:\n","    split_and_copy(cat)\n","\n","print(\"üéØ All datasets split successfully!\")"],"metadata":{"id":"i71rNTKHpiVX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **CNN Run**"],"metadata":{"id":"-HQN1p-gqMta"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, models\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","\n","# Define dataset paths for SST\n","IMG_SIZE = (512, 512)  # Input image size\n","BATCH_SIZE = 4  # Adjust based on GPU memory\n","train_input_dir = \"/content/drive/My Drive/Images/Split_Images/Parameter/train\"  # Colorful images (SST)\n","train_mask_dir = \"/content/drive/My Drive/Images/Split_Images/Parameter_Labeled/train\"  # Labeled images (HAB: 1, non-HAB: 0)\n","val_input_dir = \"/content/drive/My Drive/Images/Split_Images/Parameter/val\"\n","val_mask_dir = \"/content/drive/My Drive/Images/Split_Images/Parameter_Labeled/val\"\n","test_input_dir = \"/content/drive/My Drive/Images/Split_Images/Parameter/test\"\n","test_mask_dir = \"/content/drive/My Drive/Images/Split_Images/Parameter_Labeled/test\"\n","\n","# Function to load and preprocess images & masks\n","def process_path(image_path, mask_path):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_jpeg(image, channels=3)\n","    image = tf.image.resize(image, IMG_SIZE) / 255.0\n","\n","    mask = tf.io.read_file(mask_path)\n","    mask = tf.image.decode_jpeg(mask, channels=1)\n","    mask = tf.image.resize(mask, IMG_SIZE) / 255.0\n","\n","    return image, mask\n","\n","# Create dataset loaders\n","def create_dataset(image_dir, mask_dir):\n","    image_paths = sorted([os.path.join(image_dir, fname) for fname in os.listdir(image_dir)])\n","    mask_paths = sorted([os.path.join(mask_dir, fname) for fname in os.listdir(mask_dir)])\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((image_paths, mask_paths))\n","    dataset = dataset.map(process_path, num_parallel_calls=tf.data.AUTOTUNE)\n","    dataset = dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n","    return dataset\n","\n","train_ds = create_dataset(train_input_dir, train_mask_dir)\n","val_ds = create_dataset(val_input_dir, val_mask_dir)\n","test_ds = create_dataset(test_input_dir, test_mask_dir)\n","\n","# U-Net Model Definition\n","def unet_model(input_size=(512, 512, 3)):\n","    inputs = layers.Input(input_size)\n","\n","    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n","    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n","    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n","    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n","    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n","    pool3 = layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n","    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n","    pool4 = layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n","    conv5 = layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n","\n","    up6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n","    up6 = layers.concatenate([up6, conv4])\n","    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n","    conv6 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n","\n","    up7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n","    up7 = layers.concatenate([up7, conv3])\n","    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n","    conv7 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n","\n","    up8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n","    up8 = layers.concatenate([up8, conv2])\n","    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n","    conv8 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n","\n","    up9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n","    up9 = layers.concatenate([up9, conv1])\n","    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n","    conv9 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n","\n","    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n","    model = models.Model(inputs=[inputs], outputs=[outputs])\n","    return model\n","\n","# Train Model\n","model = unet_model()\n","model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","EPOCHS = 50\n","callbacks = [\n","    keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n","    keras.callbacks.ModelCheckpoint(\"/content/drive/My Drive/Topic_U-Net_Best_Model_chl.keras\", save_best_only=True)\n","]\n","\n","history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=callbacks)\n","\n","# Evaluate Model\n","best_model = keras.models.load_model(\"/content/drive/My Drive/Topic_U-Net_Best_Model_chl.keras\")\n","best_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n","\n","test_loss, test_acc = best_model.evaluate(test_ds)\n","print(f\"Test Accuracy: {test_acc}\")"],"metadata":{"id":"E_FOLrtuqEqY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **X_Y_Test_Parameter**"],"metadata":{"id":"Sx_BVn_crVu_"}},{"cell_type":"code","source":["import numpy as np\n","import os\n","from sklearn.model_selection import train_test_split\n","from glob import glob\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","\n","# === Set Directories ===\n","image_dir = \"/content/drive/My Drive/Split_Images/Parameter/test\"\n","mask_dir = \"/content/drive/My Drive/Split_Images/Parameter_Labeled/test\"\n","save_path = \"/content/drive/My Drive/X_Y_Test_Parameter/\"\n","os.makedirs(save_path, exist_ok=True)\n","\n","# === Load All Image and Mask Paths ===\n","image_paths = sorted(glob(os.path.join(image_dir, \"*.png\")))  # Change extension if needed\n","mask_paths = sorted(glob(os.path.join(mask_dir, \"*.png\")))\n","\n","# === Filter Only Matching Pairs ===\n","matched_image_paths = []\n","matched_mask_paths = []\n","for img_path, mask_path in zip(image_paths, mask_paths):\n","    if os.path.exists(img_path) and os.path.exists(mask_path):\n","        matched_image_paths.append(img_path)\n","        matched_mask_paths.append(mask_path)\n","\n","print(f\"Found {len(matched_image_paths)} matched image-mask pairs.\")\n","\n","# === Load and Normalize Images ===\n","X = np.array([img_to_array(load_img(p, target_size=(512, 512))) / 255.0 for p in matched_image_paths], dtype=np.float32)\n","Y = np.array([img_to_array(load_img(p, target_size=(512, 512), color_mode=\"grayscale\")) / 255.0 for p in matched_mask_paths], dtype=np.float32)\n","\n","# === Ensure Binary Masks ===\n","Y = (Y > 0.5).astype(np.uint8)\n","\n","# === Check Dataset Size ===\n","if len(X) == 0 or len(Y) == 0:\n","    raise ValueError(\"‚ùå No data found. Please check that your image and mask directories are correct and contain valid .png files.\")\n","\n","# === Split Dataset ===\n","X_trainval, X_test, Y_trainval, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n","\n","# === Save Test Set ===\n","np.save(os.path.join(save_path, \"X_test_parameter.npy\"), X_test)\n","np.save(os.path.join(save_path, \"Y_test_parameter.npy\"), Y_test)\n","\n","# === Print Summary ===\n","print(\"‚úÖ Dataset loaded, preprocessed, split, and test set saved.\")\n","print(f\"X_test shape: {X_test.shape}\")\n","print(f\"Y_test shape: {Y_test.shape}\")"],"metadata":{"id":"sLNpHoV8rVfn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Evaluation of Model**"],"metadata":{"id":"DJ-pLhXGtP6_"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import json\n","import os\n","import pandas as pd\n","from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, precision_recall_curve, accuracy_score, cohen_kappa_score, precision_score, recall_score\n","\n","# === Step 1: Select Directory to Save Outputs ===\n","output_dir = \"/content/drive/My Drive/Topic_Results\"\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","# === Step 2: Load Best Chl-a Model ===\n","model_path = \"/content/drive/My Drive/Topic_U-Net_Best_Model_chl.keras\"\n","model = tf.keras.models.load_model(model_path)\n","\n","# === Step 3: Load Test Data ===\n","X_test = np.load(\"/content/drive/My Drive/X_Y_Test_Parameter/X_test_parameter.npy\")\n","Y_test = np.load(\"/content/drive/My Drive/X_Y_Test_Parameter/Y_test_parameter.npy\")\n","\n","# === Step 4: Generate Predictions ===\n","Y_pred = model.predict(X_test, batch_size=4)\n","Y_pred_bin = (Y_pred > 0.5).astype(np.uint8)\n","\n","# === Step 5: Compute Performance Metrics ===\n","def compute_metrics(y_true, y_pred):\n","    cm = confusion_matrix(y_true.flatten(), y_pred.flatten())\n","    tn, fp, fn, tp = cm.ravel()\n","    accuracy = (tp + tn) / (tp + tn + fp + fn)\n","    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n","    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n","    iou = tp / (tp + fp + fn) if (tp + fp + fn) > 0 else 0\n","    dice = (2 * tp) / (2 * tp + fp + fn) if (2 * tp + fp + fn) > 0 else 0\n","    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","    kappa = cohen_kappa_score(y_true.flatten(), y_pred.flatten())\n","    return {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"IoU\": iou, \"Dice\": dice, \"F1-score\": f1_score, \"Kappa\": kappa}\n","\n","metrics = compute_metrics(Y_test, Y_pred_bin)\n","metrics_json_path = os.path.join(output_dir, \"Topic_model_metrics.json\")\n","with open(metrics_json_path, \"w\") as f:\n","    json.dump(metrics, f, indent=4)\n","metrics_csv_path = os.path.join(output_dir, \"Topic_model_metrics.csv\")\n","df_metrics = pd.DataFrame([metrics])\n","df_metrics.to_csv(metrics_csv_path, index=False)\n","print(\"‚úÖ Model Performance Metrics (JSON & CSV saved):\")\n","print(json.dumps(metrics, indent=4))\n","\n","# === Step 6: Confusion Matrix ===\n","cm = confusion_matrix(Y_test.flatten(), Y_pred_bin.flatten())\n","plt.figure(figsize=(24, 24))\n","sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\", xticklabels=[\"Non-Topic\", \"Topic\"], yticklabels=[\"Non-Topic\", \"Topic\"], annot_kws={\"size\": 48}, cbar_kws={\"label\": \"Count\"})\n","plt.xlabel(\"Predicted\", fontsize=40)\n","plt.ylabel(\"Actual\", fontsize=40)\n","plt.title(\"Confusion Matrix - Topic Model\", fontsize=44)\n","plt.xticks(fontsize=36)\n","plt.yticks(fontsize=36)\n","cm_path = os.path.join(output_dir, \"Topic_confusion_matrix.png\")\n","plt.savefig(cm_path, dpi=300)\n","plt.show()\n","\n","# === Step 7: ROC Curve & AUC Score ===\n","fpr, tpr, _ = roc_curve(Y_test.flatten(), Y_pred.flatten())\n","roc_auc = auc(fpr, tpr)\n","plt.figure(figsize=(24, 24))\n","plt.plot(fpr, tpr, color=\"blue\", lw=4, label=f\"AUC = {roc_auc:.4f}\")\n","plt.plot([0, 1], [0, 1], color=\"grey\", linestyle=\"--\")\n","plt.xlabel(\"False Positive Rate\", fontsize=40)\n","plt.ylabel(\"True Positive Rate\", fontsize=40)\n","plt.title(\"ROC Curve - Topic Model\", fontsize=44)\n","plt.legend(loc=\"lower right\", fontsize=36)\n","plt.xticks(fontsize=36)\n","plt.yticks(fontsize=36)\n","roc_path = os.path.join(output_dir, \"Topic_roc_curve.png\")\n","plt.savefig(roc_path, dpi=300)\n","plt.show()\n","\n","# === Step 8: Precision-Recall Curve ===\n","precision, recall, _ = precision_recall_curve(Y_test.flatten(), Y_pred.flatten())\n","plt.figure(figsize=(24, 24))\n","plt.plot(recall, precision, color=\"green\", lw=4)\n","plt.xlabel(\"Recall\", fontsize=40)\n","plt.ylabel(\"Precision\", fontsize=40)\n","plt.title(\"Precision-Recall Curve - Topic Model\", fontsize=44)\n","plt.xticks(fontsize=36)\n","plt.yticks(fontsize=36)\n","pr_path = os.path.join(output_dir, \"Topic_precision_recall_curve.png\")\n","plt.savefig(pr_path, dpi=300)\n","plt.show()\n","\n","# === Step 10: Visualize Predicted HAB Map ===\n","num_samples = 5  # Number of test samples to visualize\n","fig, axes = plt.subplots(num_samples, 3, figsize=(40, num_samples * 12))  # Increased figure size\n","\n","for i in range(num_samples):\n","    axes[i, 0].imshow(X_test[i])  # Original Chl-a image\n","    axes[i, 0].set_title(\"Parameter Image\", fontsize=36)\n","\n","    axes[i, 1].imshow(Y_test[i].squeeze(), cmap=\"gray\")  # Ground Truth\n","    axes[i, 1].set_title(\"Ground Truth (Topic)\", fontsize=36)\n","\n","    axes[i, 2].imshow(Y_pred_bin[i].squeeze(), cmap=\"gray\")  # Predicted HAB\n","    axes[i, 2].set_title(\"Predicted Topic\", fontsize=36)\n","\n","    for ax in axes[i]:\n","        ax.axis(\"off\")\n","\n","plt.tight_layout()\n","\n","# Save Final HAB Maps Image\n","hab_maps_path = os.path.join(output_dir, \"Parameter_Topic_maps.png\")\n","plt.savefig(hab_maps_path, dpi=300)\n","plt.show()\n","\n","# === Step 9: F1-Score vs. Threshold Curve ===\n","thresholds = np.linspace(0, 1, 100)\n","f1_scores = []\n","\n","# Iterate over each threshold to calculate the F1 score\n","for threshold in thresholds:\n","    Y_pred_bin = (Y_pred > threshold).astype(np.uint8)\n","    precision = precision_score(Y_test.flatten(), Y_pred_bin.flatten(), zero_division=0)\n","    recall = recall_score(Y_test.flatten(), Y_pred_bin.flatten(), zero_division=0)\n","    if precision + recall > 0:\n","        f1 = 2 * (precision * recall) / (precision + recall)\n","    else:\n","        f1 = 0\n","    f1_scores.append(f1)\n","\n","plt.figure(figsize=(24, 24))\n","plt.plot(thresholds, f1_scores, color=\"red\", lw=4)\n","plt.xlabel(\"Threshold\", fontsize=40)\n","plt.ylabel(\"F1 Score\", fontsize=40)s\n","plt.title(\"F1 Score vs. Threshold\", fontsize=44)\n","f1_path = os.path.join(output_dir, \"Parameter_f1_threshold_curve.png\")\n","plt.savefig(f1_path, dpi=300)\n","plt.show()\n","\n","print(\"‚úÖ All results saved successfully!\")"],"metadata":{"id":"nsTnrMF8tPe8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Lat-Long Save**"],"metadata":{"id":"rlOyzI32vt8s"}},{"cell_type":"code","source":["from netCDF4 import Dataset\n","import numpy as np\n","\n","# Define the path to your combined NetCDF file\n","nc_file_path = \"/content/drive/My Drive/File_name_cropped.nc\"\n","\n","# Open NetCDF file\n","nc_data = Dataset(nc_file_path, mode='r')\n","\n","# Check available variables\n","print(nc_data.variables.keys())  # This will show lat/lon variable names\n","\n","# Extract latitude and longitude\n","latitudes = nc_data.variables['latitude'][:]  # Change to the correct variable name\n","longitudes = nc_data.variables['longitude'][:]  # Change to the correct variable name\n","\n","# Convert MaskedArrays to regular NumPy arrays\n","latitudes = latitudes.filled(np.nan)  # Replace masked values with NaN\n","longitudes = longitudes.filled(np.nan)  # Replace masked values with NaN\n","\n","# Save as NumPy files for later use\n","np.save('/content/drive/My Drive/Split_Images/latitude.npy', latitudes)\n","np.save('/content/drive/My Drive/Split_Images/longitude.npy', longitudes)\n","\n","print(\"‚úÖ Latitude and Longitude extracted and saved!\")"],"metadata":{"id":"kZpz7LSlvrwT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Grad-CAM Map & Heatmap**"],"metadata":{"id":"CASigLDUwEkk"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import seaborn as sns\n","import os\n","import xarray as xr\n","from scipy.interpolate import griddata\n","\n","# Define your output directory\n","output_dir = \"/content/drive/My Drive/Topic_Results/\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load latitude & longitude from NetCDF\n","nc_file = '/content/drive/My Drive/File_name_cropped.nc'  # Change to your actual file\n","with xr.open_dataset(nc_file) as ds:\n","    latitudes = ds['latitude'].values\n","    longitudes = ds['longitude'].values\n","\n","# Create a meshgrid for lat/lon\n","grid_lon, grid_lat = np.meshgrid(longitudes, latitudes)\n","\n","# Load test images\n","X_test_chla = np.load('/content/drive/My Drive/Split_Images/X_Y_Test_Parameter/X_test_parameter.npy')\n","\n","# Load the best Topic model (for Parameter)\n","model = tf.keras.models.load_model('/content/drive/My Drive/Topic_U-Net_Best_Model_chl.keras')\n","\n","# Select a test image\n","img_index = 0  # Change this index if needed\n","input_image = np.expand_dims(X_test_parameter[img_index], axis=0)\n","\n","# Get model's last convolutional layer\n","last_conv_layer = model.get_layer('conv2d_18')  # Change if needed\n","\n","# Grad-CAM Heatmap\n","grad_model = tf.keras.models.Model([model.inputs], [last_conv_layer.output, model.output])\n","with tf.GradientTape() as tape:\n","    conv_output, predictions = grad_model(input_image)\n","    loss = predictions[:, :, :, 0]  # Target class (HAB)\n","\n","grads = tape.gradient(loss, conv_output)\n","weights = tf.reduce_mean(grads, axis=(0, 1, 2))\n","cam_output = np.dot(conv_output[0], weights[..., np.newaxis])\n","cam_output = np.squeeze(cam_output)\n","\n","# Normalize & Resize Heatmap\n","cam_output = np.maximum(cam_output, 0)\n","cam_output /= np.max(cam_output)\n","heatmap = cv2.resize(cam_output, (X_test_chla.shape[1], X_test_chla.shape[2]))\n","\n","# Interpolate to match lat/lon grid\n","lat_2d, lon_2d = np.meshgrid(np.linspace(latitudes.min(), latitudes.max(), heatmap.shape[0]),\n","                             np.linspace(longitudes.min(), longitudes.max(), heatmap.shape[1]),\n","                             indexing='ij')\n","heatmap_resized = griddata((lon_2d.ravel(), lat_2d.ravel()), heatmap.ravel(), (grid_lon, grid_lat), method='cubic')\n","\n","# Rotate heatmap by 180 degrees\n","heatmap_resized = np.rot90(heatmap_resized, 2)\n","\n","# Apply mirror flip\n","heatmap_resized = np.fliplr(heatmap_resized)\n","\n","# Plot Grad-CAM Heatmap\n","plt.figure(figsize=(72, 54))\n","plt.contourf(grid_lon, grid_lat, heatmap_resized, cmap='jet', alpha=0.75)\n","cbar = plt.colorbar(fraction=0.046, pad=0.04)\n","cbar.set_label(\"Model Focus Intensity\", fontsize = 50)\n","cbar.ax.tick_params(labelsize=40)  # Increase size of color bar numbers\n","plt.title(\"Grad-CAM Heatmap of Topic\", fontsize=60)\n","plt.xlabel(\"Longitude\", fontsize=50)\n","plt.ylabel(\"Latitude\", fontsize=50)\n","plt.xticks(fontsize=50)\n","plt.yticks(fontsize=50)\n","plt.savefig(os.path.join(output_dir, 'GradCAM_Heatmap_Topic.png'))\n","plt.show()\n","\n","# ------------------------- #\n","# ‚úÖ HAB Probability Heatmap\n","# ------------------------- #\n","\n","# Get model predictions\n","preds_chla = model.predict(input_image)\n","probabilities = preds_chla[0, :, :, 0]\n","\n","# Interpolate probability heatmap to lat/lon\n","detected_prob_resized = griddata((lon_2d.ravel(), lat_2d.ravel()), probabilities.ravel(), (grid_lon, grid_lat), method='cubic')\n","\n","# Rotate probability heatmap by 180 degrees\n","#detected_prob_resized = np.rot90(detected_prob_resized, 2)\n","\n","# Apply mirror flip\n","detected_prob_resized = np.fliplr(detected_prob_resized)\n","\n","# Fix the flipped heatmap orientation\n","detected_prob_resized = np.flipud(np.fliplr(detected_prob_resized))\n","\n","# Plot Probability Heatmap with customized latitude and longitude\n","plt.figure(figsize=(72, 54))\n","\n","# Plot heatmap using imshow to create mappable object for colorbar\n","im = plt.imshow(detected_prob_resized, cmap='jet', alpha=0.75)\n","\n","# Add colorbar\n","cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n","cbar.set_label(\"Topic Probability\", fontsize=50)\n","cbar.ax.tick_params(labelsize=40)  # Increase size of color bar numbers\n","\n","plt.title(\"Topic Probability Heatmap\", fontsize=60)\n","plt.xlabel(\"Longitude\", fontsize=50)\n","plt.ylabel(\"Latitude\", fontsize=50)\n","\n","# Set proper latitude and longitude ticks\n","plt.xticks(ticks=np.linspace(0, detected_prob_resized.shape[1] - 1, num=5), labels=np.round(np.linspace(longitudes.min(), longitudes.max(), num=5), 2), fontsize=50)\n","plt.yticks(ticks=np.linspace(0, detected_prob_resized.shape[0] - 1, num=5), labels=np.round(np.linspace(latitudes.min(), latitudes.max(), num=5), 2), fontsize=50)\n","\n","# Invert the y-axis to fix the latitude orientation\n","plt.gca().invert_yaxis()\n","\n","plt.savefig(os.path.join(output_dir, 'Topic_Probability_Heatmap.png'))\n","plt.show()\n","\n","print(f\"üî• Heatmaps saved in: {output_dir}\")"],"metadata":{"id":"fKXx2GVwwECe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Map with Shapefile for better visualization**"],"metadata":{"id":"Mvmbq2BvxQtf"}},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","import seaborn as sns\n","import os\n","import xarray as xr\n","from scipy.interpolate import griddata\n","import geopandas as gpd\n","\n","# Define your output directory\n","output_dir = \"/content/drive/My Drive/Topic_Results/\"\n","os.makedirs(output_dir, exist_ok=True)\n","\n","# Load the shapefile (change path accordingly)\n","shapefile_path = \"/content/drive/My Drive/Shapefile.shp\"  # Update with your actual path\n","gdf = gpd.read_file(shapefile_path)\n","\n","# Ensure shapefile CRS matches NetCDF coordinates\n","if gdf.crs is None:\n","    gdf.set_crs(epsg=4326, inplace=True)  # Assuming lat/lon in degrees\n","\n","gdf = gdf.to_crs(epsg=4326)  # Convert to WGS84 (EPSG:4326) if needed\n","\n","# Ensure shapefile CRS matches NetCDF coordinates\n","if gdf1.crs is None:\n","    gdf1.set_crs(epsg=4326, inplace=True)  # Assuming lat/lon in degrees\n","\n","gdf1 = gdf1.to_crs(epsg=4326)  # Convert to WGS84 (EPSG:4326) if needed\n","\n","# Load latitude & longitude from NetCDF\n","nc_file = '/content/drive/My Drive/File_name_cropped.nc'  # Change to your actual file\n","with xr.open_dataset(nc_file) as ds:\n","    latitudes = ds['latitude'].values\n","    longitudes = ds['longitude'].values\n","\n","# Create a meshgrid for lat/lon\n","grid_lon, grid_lat = np.meshgrid(longitudes, latitudes)\n","\n","# Load test images\n","X_test_chla = np.load('/content/drive/My Drive/Split_Images/X_Y_Test_Parameter/X_test_parameter.npy')\n","\n","# Load the best Topic model\n","model = tf.keras.models.load_model('/content/drive/My Drive/Topic_U-Net_Best_Model_chl.keras')\n","\n","# Select a test image\n","img_index = 0  # Change this index if needed\n","input_image = np.expand_dims(X_test_parameter[img_index], axis=0)\n","\n","# Get model's last convolutional layer\n","last_conv_layer = model.get_layer('conv2d_18')  # Change if needed\n","\n","# Grad-CAM Heatmap\n","grad_model = tf.keras.models.Model([model.inputs], [last_conv_layer.output, model.output])\n","with tf.GradientTape() as tape:\n","    conv_output, predictions = grad_model(input_image)\n","    loss = predictions[:, :, :, 0]  # Target class (HAB)\n","\n","grads = tape.gradient(loss, conv_output)\n","weights = tf.reduce_mean(grads, axis=(0, 1, 2))\n","cam_output = np.dot(conv_output[0], weights[..., np.newaxis])\n","cam_output = np.squeeze(cam_output)\n","\n","# Normalize & Resize Heatmap\n","cam_output = np.maximum(cam_output, 0)\n","cam_output /= np.max(cam_output)\n","heatmap = cv2.resize(cam_output, (X_test_chla.shape[1], X_test_chla.shape[2]))\n","\n","# Interpolate to match lat/lon grid\n","lat_2d, lon_2d = np.meshgrid(np.linspace(latitudes.min(), latitudes.max(), heatmap.shape[0]),\n","                             np.linspace(longitudes.min(), longitudes.max(), heatmap.shape[1]),\n","                             indexing='ij')\n","heatmap_resized = griddata((lon_2d.ravel(), lat_2d.ravel()), heatmap.ravel(), (grid_lon, grid_lat), method='cubic')\n","\n","# Rotate heatmap by 180 degrees\n","heatmap_resized = np.rot90(heatmap_resized, 2)\n","\n","# Apply mirror flip\n","heatmap_resized = np.fliplr(heatmap_resized)\n","\n","# Plot Grad-CAM Heatmap\n","plt.figure(figsize=(72, 54))\n","plt.contourf(grid_lon, grid_lat, heatmap_resized, cmap='jet', alpha=0.75)\n","\n","# Overlay shapefile\n","gdf1.plot(ax=plt.gca(), facecolor=\"peru\", edgecolor=\"black\", linewidth=3)    # Change color and linewidth if needed\n","\n","# Overlay shapefile\n","gdf.plot(ax=plt.gca(), facecolor=\"burlywood\", edgecolor=\"black\", linewidth=3)    # Change color and linewidth if needed\n","\n","# Overlay shapefile\n","#gdf.boundary.plot(ax=plt.gca(), color=\"Black\", edgecolor=\"Black\", linewidth=5)  # Change color and linewidth if needed\n","\n","cbar = plt.colorbar(fraction=0.046, pad=0.04)\n","cbar.set_label(\"Model Focus Intensity\", fontsize = 50)\n","cbar.ax.tick_params(labelsize=40)  # Increase size of color bar numbers\n","plt.title(\"Grad-CAM Heatmap of Topic\", fontsize=60)\n","plt.xlabel(\"Longitude (Degrees_East)\", fontsize=50)\n","plt.ylabel(\"Latitude (Degrees_North)\", fontsize=50)\n","plt.xticks(fontsize=50)\n","plt.yticks(fontsize=50)\n","plt.savefig(os.path.join(output_dir, 'GradCAM_Heatmap_Topic_Shp.png'))\n","plt.show()\n","\n","print(f\"üî• Heatmap saved in: {output_dir}\")"],"metadata":{"id":"vxfLX2zaxQfD"},"execution_count":null,"outputs":[]}]}